import re
import requests

import base64
import os
from fernet import Fernet
from uuid import uuid4
import json

show_lines = False
open_links = False
disable_fernet = True # only enable if you are fine with eval being used.

# import regex
# should detect any imports in the script, should return the imports and should end if a semicolon is detected
import_regex = re.compile(r"import\s+([a-zA-Z0-9_]+)")

# detect texts in quotes
# should detect any texts in quotes, single quotes and double quotes, should return the texts in quotes and should end if a semicolon is detected
text_in_quotes_regex = re.compile(r"['\"](.*?)['\"]")

def scan_line(lines):
    global show_lines
    extra_data = []
    
    for line in lines.splitlines():
        imports = import_regex.findall(line)

        texts = text_in_quotes_regex.findall(line)
        if not imports and not texts:
            return

        if show_lines:
            if imports: print(f"Imports: {imports}")
            if texts: print(f"Texts: {texts}")

        for text in texts:
            if "http" in text:
                extra_data.append({
                    "type": "url",
                    "data": text
                })
            
                print(f"Detected URL: {text}")
                if ".exe" in text:
                    print(f"DANGER: Detected .exe in URL, proceed with caution. {text}")
                
                if open_links and ".exe" not in text:
                    response = requests.get(text)

                    if response.status_code == 200:
                        extra_data.append({
                            "type": "opened link",
                            "data": scan_line(response.text)
                        })
                    else:
                        print("Failed to open link.")
                        extra_data.append({
                            "type": "error",
                            "data": f"Error: {response.status_code}",
                            "URL": text
                        })

        if "Fernet" in imports and not disable_fernet:
            print("Detected Fernet.")
            juicy_texts = []
            for text in texts:
                if len(text) > 15 and not "pip" in text and not "install" in text:
                    juicy_texts.append(text)

            decrypted = eval(f"Fernet(b'{juicy_texts[0]}').decrypt(b'{juicy_texts[1]}')")

            if show_lines:
                print(decrypted)

            extra_data.append({
                "type": "Fernet",
                "data": scan_line(decrypted.decode()),
                "information": decrypted.decode()
            })

        if "base64" in imports:
            print("Detected Base64.")
            for text in texts:
                if len(text) > 15:
                    if show_lines:
                        print(base64.b64decode(text).decode())
                    extra_data.append({
                        "type": "base64",
                        "data": scan_line(base64.b64decode(text).decode()),
                        "information": base64.b64decode(text).decode()
                    })

    return extra_data

with open("./data.json", "w") as f:
    json.dump({}, f)

with open("./detections/detected_scripts.txt", "r") as f:
    for line in f.readlines():
        line_id = uuid4()

        extra_data = scan_line(line)
        with open("./data.json", "r") as f:
            data = json.load(f)

        data[str(line_id)] = extra_data
        with open("./data.json", "w") as f:
            json.dump(data, f, indent=4)

        print(f"Line ID: {line_id} dumped")
